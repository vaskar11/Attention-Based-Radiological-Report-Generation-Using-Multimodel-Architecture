{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4474,"status":"ok","timestamp":1741586590980,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"3qpfKOVN5SjA","outputId":"b496ec33-5072-42d2-b52d-ba804c912fa3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n","Requirement already satisfied: gast\u003c=0.4.0,\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.70.0)\n","Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.12.1)\n","Requirement already satisfied: jax\u003e=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n","Requirement already satisfied: keras\u003c2.13,\u003e=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n","Requirement already satisfied: numpy\u003c1.24,\u003e=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c5.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.1.0)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n","Requirement already satisfied: tensorboard\u003c2.13,\u003e=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n","Requirement already satisfied: tensorflow-estimator\u003c2.13,\u003e=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.5.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.12.2)\n","Requirement already satisfied: wrapt\u003c1.15,\u003e=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow==2.12.0) (0.45.1)\n","Requirement already satisfied: jaxlib\u003c=0.4.30,\u003e=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax\u003e=0.3.15-\u003etensorflow==2.12.0) (0.4.30)\n","Requirement already satisfied: ml-dtypes\u003e=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax\u003e=0.3.15-\u003etensorflow==2.12.0) (0.4.1)\n","Requirement already satisfied: scipy\u003e=1.9 in /usr/local/lib/python3.11/dist-packages (from jax\u003e=0.3.15-\u003etensorflow==2.12.0) (1.13.1)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (2.38.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c1.1,\u003e=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (1.0.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (3.7)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (3.1.3)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (5.5.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (0.4.1)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib\u003c1.1,\u003e=0.5-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (2.0.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (3.4.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (2.3.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (2025.1.31)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (3.0.2)\n","Requirement already satisfied: pyasn1\u003c0.7.0,\u003e=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (0.6.1)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c1.1,\u003e=0.5-\u003etensorboard\u003c2.13,\u003e=2.12-\u003etensorflow==2.12.0) (3.2.2)\n"]}],"source":["!pip install tensorflow==2.12.0"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":17475,"status":"ok","timestamp":1741586610702,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"m9fuu1Zj2nSV"},"outputs":[],"source":["import os\n","import re\n","import cv2\n","import time\n","import tarfile\n","import datetime\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow import concat\n","from tensorflow import repeat\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","warnings.filterwarnings('ignore')\n","from sklearn.utils import shuffle\n","from skimage.transform import resize\n","import nltk.translate.bleu_score as bleu\n","from tensorflow.keras.models import Model\n","from google.colab.patches import cv2_imshow\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.backend import expand_dims\n","from nltk.translate.bleu_score import sentence_bleu\n","from tensorflow.keras.layers import TimeDistributed\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.layers import concatenate, Concatenate\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.applications.densenet import preprocess_input\n","from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM, Layer, Dropout, GRU"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1741586610721,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"T7lVQxGJ5QkS","outputId":"ba0df0c2-20f8-4ad2-f2fd-ebac9d1826de"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.12.0'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":174,"status":"ok","timestamp":1741586610897,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"8S3GexqM6IYb"},"outputs":[],"source":["import flask\n","from werkzeug.utils import secure_filename\n","from flask import Flask, redirect, url_for, request, render_template, jsonify"]},{"cell_type":"markdown","metadata":{"id":"NxuKzSdhOOCm"},"source":["### Change dir to current working dir"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1741586610905,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"Gu_28zY86LOQ"},"outputs":[],"source":["os.chdir(\"/content/drive/MyDrive/deployment\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1741586611191,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"TLBGSW9s60ru","outputId":"25e45710-aa2c-4f20-ab18-4f68deae9733"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/  deployment.ipynb  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mstatic\u001b[0m/  \u001b[01;34mtemplates\u001b[0m/\n"]}],"source":["ls"]},{"cell_type":"markdown","metadata":{"id":"9FbjwhcMOT63"},"source":["### Loading CheXNet Model :"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":16945,"status":"ok","timestamp":1741586629534,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"pt3Ye9Ln6da_"},"outputs":[],"source":["image_model = DenseNet121(weights='models/brucechou1983_CheXNet_Keras_0.3.0_weights.h5', classes = 14, input_shape=(256,256,3))\n","model = Model(image_model.input, image_model.layers[-2].output)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1124,"status":"ok","timestamp":1741586630664,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"qnmOttoc6r05"},"outputs":[],"source":["train = np.load('data/train.npy',allow_pickle=True)\n","test = np.load('data/test.npy',allow_pickle=True)\n","validation = np.load('data/validation.npy',allow_pickle=True)\n","\n","columns = [\"front X-Ray\", \"lateral X-Ray\", \"findings\", \"dec_ip\", \"dec_op\", \"image_features\"]\n","\n","train = pd.DataFrame(train, columns = columns)\n","test = pd.DataFrame(test, columns = columns)\n","validation = pd.DataFrame(validation, columns = columns)\n","\n","#Reshaping the Image tensors for training\n","train_image_features = np.vstack(train.image_features).astype(np.float)\n","validation_image_features = np.vstack(validation.image_features).astype(np.float)"]},{"cell_type":"markdown","metadata":{"id":"68OLnML1OY2k"},"source":["### Text Tokenization :"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":997,"status":"ok","timestamp":1741586631665,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"hvQhx5ON72Y0"},"outputs":[],"source":["\n","token = Tokenizer( filters='!\"#$%\u0026()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n')\n","token.fit_on_texts(train['findings'])\n","\n","token.word_index['\u003cpad\u003e'] = 0\n","token.index_word[0] = '\u003cpad\u003e'\n","vocab_size = len(token.word_index) + 1\n","\n","#sequence in train and validation\n","train_inp_dec = token.texts_to_sequences(train.dec_ip)\n","train_op_dec = token.texts_to_sequences(train.dec_op)\n","val_inp_dec = token.texts_to_sequences(validation.dec_ip)\n","val_op_dec = token.texts_to_sequences(validation.dec_op)\n","\n","#padding in the train and validation\n","max_len = 100\n","decoder_input = pad_sequences(train_inp_dec, maxlen=max_len, padding='post')\n","decoder_output =  pad_sequences(train_op_dec, maxlen=max_len, padding='post')\n","Validation_decoder_input = pad_sequences(val_inp_dec, maxlen=max_len, padding='post')\n","Validation_decoder_output = pad_sequences(val_op_dec, maxlen=max_len, padding='post')\n","\n","word_idx = {}\n","idx_word = {}\n","for key, value in (token.word_index).items():\n","    word_idx[key] = value\n","    idx_word[value] = key"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":633,"status":"ok","timestamp":1741586632304,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"WdZpG52o8YHR"},"outputs":[],"source":["batch_size     = 50\n","Buffer_size    = 500\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(((train_image_features, decoder_input), decoder_output))\n","train_dataset = train_dataset.shuffle(Buffer_size).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","validation_dataset = tf.data.Dataset.from_tensor_slices(((validation_image_features,Validation_decoder_input),Validation_decoder_output))\n","validation_dataset = validation_dataset.shuffle(Buffer_size).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"]},{"cell_type":"markdown","metadata":{"id":"143Kak21Ocor"},"source":["### Loading Model Architecture :"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":80,"status":"ok","timestamp":1741586632388,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"C1a-JlT-8csC"},"outputs":[],"source":["class Encoder(tf.keras.Model):\n","    '''\n","    Encoder model -- That takes a input sequence and returns output sequence\n","    '''\n","    def __init__(self,lstm_units):\n","        super().__init__()\n","\n","        self.lstm_units = lstm_units\n","        self.dense      = Dense(self.lstm_units, kernel_initializer=\"glorot_uniform\", name = 'encoder_dense_layer')\n","\n","    def initialize_states(self,batch_size):\n","\n","        self.batch_size  = batch_size\n","        self.enc_h       = tf.zeros((self.batch_size, self.lstm_units))\n","\n","        return self.enc_h\n","\n","    def call(self,x):\n","\n","        # x : image_data\n","        encoder_output = self.dense(x)\n","\n","        return encoder_output\n","\n","\n","class Attention(tf.keras.layers.Layer):\n","    '''\n","    Class that calculates score based on the scoring_function using Bahdanu attention mechanism.\n","    '''\n","    def __init__(self,attention_units):\n","        super().__init__()\n","\n","        self.attention_units = attention_units\n","\n","        self.w1_Dense    =  tf.keras.layers.Dense(self.attention_units, kernel_initializer=\"glorot_uniform\", name='Concat_w1_Dense')\n","        self.w2_Dense    =  tf.keras.layers.Dense(self.attention_units, kernel_initializer=\"glorot_uniform\", name='Concat_w2_Dense')\n","        self.Concat_Dense=  tf.keras.layers.Dense(1, kernel_initializer=\"glorot_uniform\", name = 'Concat_Dense_layer')\n","\n","    def call(self,x):\n","\n","        self.decoder_hidden_state, self.encoder_output = x\n","        self.decoder_hidden_state = tf.expand_dims(self.decoder_hidden_state,axis = 1)\n","\n","        score = self.Concat_Dense(tf.nn.tanh(self.w1_Dense(self.decoder_hidden_state) + self.w2_Dense(self.encoder_output)))\n","\n","        att_weights    = tf.nn.softmax(score, axis=1)\n","        context_vector = att_weights * self.encoder_output\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","        return context_vector,att_weights\n","\n","\n","class OneStepDecoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, lstm_units, attention_units):\n","        super().__init__()\n","\n","        self.lstm_units     = lstm_units\n","        self.vocab_size     = vocab_size\n","        self.embedding_dim  = embedding_dim\n","        self.attention_units= attention_units\n","\n","        self.dense       = Dense(self.vocab_size, kernel_initializer=\"glorot_uniform\", name ='onestep_dense')\n","        self.attention   = Attention( self.attention_units)\n","        self.decoder_emb = Embedding(self.vocab_size, self.embedding_dim, trainable = True , name = 'Decoder_embedding')\n","        self.decoder_gru = GRU(self.lstm_units, return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n","\n","\n","        self.dropout1 = Dropout(0.3,name = 'dropout1')\n","        self.dropout2 = Dropout(0.3,name = 'dropout2')\n","        self.dropout3 = Dropout(0.3,name = 'dropout3')\n","\n","    @tf.function\n","    def call(self,x,training=None):\n","\n","        self.input_to_decoder, self.encoder_output, self.state_h = x\n","\n","        embedded_output = self.decoder_emb(self.input_to_decoder)\n","        embedded_output = self.dropout1(embedded_output)\n","\n","        y = [self.state_h,self.encoder_output]\n","        context_vector, att_weights = self.attention(y)\n","\n","        concated_decoder_input = tf.concat([tf.expand_dims(context_vector, 1),embedded_output], -1)\n","        concated_decoder_input = self.dropout2(concated_decoder_input)\n","\n","        output_gru, hidden_state = self.decoder_gru(concated_decoder_input, initial_state=self.state_h)\n","\n","        output_gru = tf.reshape(output_gru, (-1, output_gru.shape[2]))\n","        output_gru = self.dropout3(output_gru)\n","\n","        output = self.dense(output_gru)\n","\n","        return output,hidden_state,att_weights,context_vector\n","\n","\n","class Decoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, lstm_units, attention_units):\n","        super().__init__()\n","\n","        self.lstm_units     = lstm_units\n","        self.vocab_size     = vocab_size\n","        self.embedding_dim  = embedding_dim\n","        self.attention_units= attention_units\n","\n","        self.onestepdecoder = OneStepDecoder(self.vocab_size, self.embedding_dim, self.lstm_units, self.attention_units)\n","\n","    @tf.function\n","    def call(self, x,training=None):\n","\n","        self.input_to_decoder, self.encoder_output, self.decoder_hidden_state = x\n","        all_outputs = tf.TensorArray(tf.float32,size = self.input_to_decoder.shape[1], name = 'output_arrays' )\n","\n","        for timestep in tf.range(self.input_to_decoder.shape[1]):\n","\n","            y = [self.input_to_decoder[:,timestep:timestep+1],self.encoder_output, self.decoder_hidden_state]\n","            output,hidden_state,att_weights,context_vector = self.onestepdecoder(y)\n","\n","            self.decoder_hidden_state = hidden_state\n","            all_outputs = all_outputs.write(timestep,output)\n","\n","        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n","\n","        return all_outputs\n","\n","\n","class Encoder_decoder(tf.keras.Model):\n","    \"\"\"\n","     # Intialize encoder states, Pass the encoder_sequence to the embedding layer\n","     # Decoder initial states are encoder final states, Initialize it accordingly\n","     # Pass the decoder sequence,encoder_output,decoder states to Decoder\n","     # return the decoder output\n","\n","    \"\"\"\n","    def __init__(self, vocab_size, embedding_dim, lstm_units, attention_units, batch_size):\n","        super().__init__()\n","\n","        self.vocab_size     = vocab_size\n","        self.batch_size     = batch_size\n","        self.lstm_units     = lstm_units\n","        self.embedding_dim  = embedding_dim\n","        self.attention_units= attention_units\n","\n","        self.encoder = Encoder(self.lstm_units)\n","        self.decoder = Decoder(vocab_size, embedding_dim, lstm_units, attention_units)\n","        self.dense   = Dense(self.vocab_size, kernel_initializer=\"glorot_uniform\", name = 'enc_dec_dense')\n","\n","\n","    def call(self,data):\n","\n","        self.inputs, self.outputs = data[0], data[1]\n","\n","        self.encoder_hidden = self.encoder.initialize_states(self.batch_size)\n","        self.encoder_output = self.encoder(self.inputs)\n","\n","        x = [self.outputs,self.encoder_output,self.encoder_hidden]\n","        output = self.decoder(x)\n","\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"GQ_dYMdbOjiF"},"source":["### Optimization adn loss function"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":58,"status":"ok","timestamp":1741586632452,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"7m0O0Rpt9t6t"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"]},{"cell_type":"markdown","metadata":{"id":"mnyGUIl_Onxj"},"source":["### Load model"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213966,"status":"ok","timestamp":1741586846439,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"zwzN_S8R9wAX","outputId":"cb4c3d46-c00f-4bf8-fbac-324eea197d6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["64/64 [==============================] - 213s 3s/step - loss: 1.4258 - val_loss: 1.3869\n"]},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7cffb5ce2010\u003e"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["lstm_units     = 256\n","embedding_dim  = 300\n","attention_units= 64\n","tf.keras.backend.clear_session()\n","Attention_model = Encoder_decoder(vocab_size,embedding_dim,lstm_units,attention_units,batch_size)\n","Attention_model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_function)\n","Attention_model.fit(train_dataset, validation_data=validation_dataset, epochs=1, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"DjQGhM2DOqkM"},"source":["### Load our trained model"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1741586846446,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"xbhLv3Nk9_8l"},"outputs":[],"source":["Attention_model.load_weights('models/Attention_model03.h5')"]},{"cell_type":"markdown","metadata":{"id":"__45UFq_OwwB"},"source":["### Link for hosting the code in colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1569,"status":"ok","timestamp":1741577429840,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"4HM2d3mDH_nD","outputId":"84ba76fd-036f-416b-80e4-3dc6b03b4d80"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://b7kzrhrzop-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"]}],"source":["# from google.colab.output import eval_js\n","# print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"]},{"cell_type":"markdown","metadata":{"id":"tUgmksQfO4de"},"source":["### Prediction, inference and deployment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15932,"status":"ok","timestamp":1741577445798,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"ZSy6mzgodSVF","outputId":"b9db8c8e-a33e-4e64-9429-94c9751d9520"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]}],"source":["# def load_image(img_name):\n","#   \"\"\"Loads image in array format\"\"\"\n","\n","#   image = Image.open(img_name)\n","#   X = np.asarray(image.convert(\"RGB\"))\n","#   X = np.asarray(X)\n","#   X = preprocess_input(X)\n","#   X = resize(X, (256,256,3))\n","#   X = np.expand_dims(X, axis=0)\n","#   X = np.asarray(X)\n","\n","#   return X\n","\n","# def preprocess(image1_path,image2_path):\n","#   '''\n","#     input -- dataframe(df)\n","#     output -- dataframe(df)\n","#     process - convert images into 256 X 256, then using CHeXNET model generate tensor(concate two image tensor)\n","#   '''\n","#   path = '/content/images/'\n","\n","#   image_features = []\n","#   for i in range(len(image1_path)):\n","\n","#     i1 = load_image(image1_path)\n","#     i2 = load_image(image2_path)\n","#     img1_features = model.predict(i1)\n","#     img2_features = model.predict(i2)\n","#     img1_features = np.vstack(img1_features).astype(np.float)\n","#     img2_features = np.vstack(img2_features).astype(np.float)\n","\n","#     tensor = np.concatenate((img1_features, img2_features), axis=1)\n","\n","#   return tensor\n","\n","\n","# def predict_report(image1, image2):\n","#     '''\n","#     Input - two image and image path\n","#     output - return medical report of the images\n","#     This function takes images and using encoder decoder model\n","#     return medical report of the images\n","#     The function predicts the sentence using beam search\n","#     '''\n","\n","#     img_tensor     = preprocess(image1, image2)\n","#     image_features = np.vstack(img_tensor).astype(np.float)\n","\n","#     result = ''\n","#     initial_state  = Attention_model.layers[0].initialize_states(1)\n","#     sequences      = [['\u003cstart\u003e', initial_state, 0]]\n","\n","#     encoder_output       = Attention_model.layers[0](image_features)\n","#     decoder_hidden_state = initial_state\n","\n","#     max_len = 75\n","#     beam_width = 3\n","#     finished_seq = []\n","\n","#     for i in range(max_len):\n","#         new_seq = []\n","#         all_probable = []\n","\n","#         for seq,state,score in sequences:\n","\n","#             cur_vec = np.reshape(word_idx[seq.split(\" \")[-1]],(1,1))\n","#             decoder_hidden_state = state\n","#             x = [cur_vec, encoder_output, decoder_hidden_state]\n","#             output,hidden_state,att_weights,context_vector = Attention_model.get_layer('decoder').onestepdecoder(x)\n","#             output = tf.nn.softmax(output)\n","#             top_words = np.argsort(output).flatten()[-beam_width:]\n","#             for index in top_words:\n","\n","#                 predicted = [seq + ' '+ idx_word[index], hidden_state, score-np.log(np.array(output).flatten()[index])]\n","#                 all_probable.append(predicted)\n","\n","#         sequences = sorted(all_probable, key = lambda l: l[2])[:beam_width]\n","\n","#         count = 0\n","#         for seq,state,score in sequences:\n","#             if seq.split(\" \")[-1] == '\u003cend\u003e':\n","#                 score = score/len(seq)\n","#                 finished_seq.append([seq,state,score])\n","#                 count+=1\n","#             else:\n","#                 new_seq.append([seq,state,score])\n","\n","#         sequences = new_seq\n","#         beam_width= beam_width - count\n","#         if not sequences:\n","#             break\n","#         else:\n","#             continue\n","\n","#     if len(finished_seq) \u003e0:\n","#           finished_seq = sorted(finished_seq, reverse=True, key = lambda l: l[2])\n","#           sequences = finished_seq[-1]\n","#           return sequences[0][8:-5]\n","#     else:\n","#           return new_seq[-1][0]\n","\n","\n","# from flask import Flask, render_template, request , redirect, url_for, session\n","# from werkzeug.utils import secure_filename\n","# import os\n","\n","\n","# template_folder='templates'\n","# static_folder='static'\n","\n","# app = Flask(__name__, template_folder=template_folder,static_folder=static_folder)\n","\n","\n","# # Ensure static/uploads exists\n","# UPLOAD_FOLDER = 'static/uploads'\n","\n","# os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n","\n","# app.secret_key = 'your_secret_key'  # Needed for session management\n","# @app.route(\"/\",methods=['GET','POST'])\n","# def login():\n","#   USER= 'admin'\n","#   PASSWORD= 'admin'\n","#   if request.method=='POST':\n","#     username= request.form['username']\n","#     password= request.form['password']\n","\n","#     if username==USER and password==PASSWORD:\n","#       session['logged_in'] = True  # Set session variable\n","#       return render_template(\"index.html\")\n","#     else:\n","#       message= \"Wrong username or password. Try again!\"\n","#       return render_template(\"login.html\", message=message)\n","\n","#   else:\n","#     return render_template(\"login.html\")\n","\n","\n","# @app.route(\"/logout\")\n","# def logout():\n","#     session.pop('logged_in', None)  # Remove session variable\n","#     return render_template(\"login.html\")\n","\n","\n","\n","# @app.route('/home')\n","# def home():\n","#   # if not session.get('logged_in'):  # Check if user is logged in\n","#   #       return render_template(\"login.html\")\n","#   return render_template('index.html')\n","\n","\n","\n","\n","\n","# @app.route('/predict',methods=['POST'] )\n","# def predict_caption():\n","\n","\n","#       front_XRay   = request.files['file_1']\n","#       lateral_XRay = request.files['file_2']\n","#       print(front_XRay.filename)\n","#       print(lateral_XRay.filename)\n","\n","#       # Save files in static/uploads/\n","#       front_XRay_path = os.path.join(UPLOAD_FOLDER, secure_filename(front_XRay.filename))\n","#       lateral_XRay_path = os.path.join(UPLOAD_FOLDER, secure_filename(lateral_XRay.filename))\n","\n","#       front_XRay.save(front_XRay_path)\n","#       lateral_XRay.save(lateral_XRay_path)\n","\n","#       result = predict_report(front_XRay_path,lateral_XRay_path)\n","\n","#       return render_template('prediction.html', prediction_text=result, front_XRay=secure_filename(front_XRay.filename), lateral_XRay=secure_filename(lateral_XRay.filename))\n","\n","\n","# if __name__ == '__main__':\n","#     app.run()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4380,"status":"ok","timestamp":1741586858370,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"HBTq07r0cnWN","outputId":"7f4467f5-da66-4644-d91e-d93266ce1037"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n","Requirement already satisfied: Flask\u003e=0.8 in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (3.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n","Requirement already satisfied: Werkzeug\u003e=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (3.1.3)\n","Requirement already satisfied: Jinja2\u003e=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (3.1.5)\n","Requirement already satisfied: itsdangerous\u003e=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (2.2.0)\n","Requirement already satisfied: click\u003e=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (8.1.8)\n","Requirement already satisfied: blinker\u003e=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (1.9.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003eflask-ngrok) (3.4.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-\u003eflask-ngrok) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003eflask-ngrok) (2.3.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests-\u003eflask-ngrok) (2025.1.31)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2\u003e=3.1.2-\u003eFlask\u003e=0.8-\u003eflask-ngrok) (3.0.2)\n"]}],"source":["!pip install flask-ngrok\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3600,"status":"ok","timestamp":1741586861974,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"2obOD2vmh5Uc","outputId":"9c70af08-d804-45e6-c2e4-dcd1a19e8ed1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n","Requirement already satisfied: PyYAML\u003e=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"]}],"source":["!pip install pyngrok\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":644,"status":"ok","timestamp":1741586862622,"user":{"displayName":"bhaskar subedi","userId":"05040228180341140141"},"user_tz":-345},"id":"cpKW2SoziBsX","outputId":"ee3cb8f6-3ebd-4a1d-d552-e37301b6f42f"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://f89f-34-74-133-147.ngrok-free.app\n"]}],"source":["from pyngrok import ngrok\n","from flask import Flask\n","ngrok.set_auth_token('2tw2hVGVy5gjl9Tjltx9M4N8j4k_XvtVJELukuPAvfT5hC1Q')\n","# Specify the port within the config dictionary:\n","public_url = ngrok.connect(bind_tls=True, addr=5000).public_url\n","print(public_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WDvXZRbofhpy"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://5678-34-74-133-147.ngrok-free.app\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:07:56] \"GET / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:07:57] \"GET /static/styles/mystyle.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:07:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:08:16] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:08:17] \"GET /static/js/myjs.js HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:08:17] \"GET /static/styles/index.css HTTP/1.1\" 200 -\n"]},{"name":"stdout","output_type":"stream","text":["CXR1_1_IM-0001-4001.png\n","CXR1_1_IM-0001-3001.png\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 0s 285ms/step\n","1/1 [==============================] - 0s 252ms/step\n","1/1 [==============================] - 0s 264ms/step\n","1/1 [==============================] - 0s 254ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 254ms/step\n","1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 262ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 266ms/step\n","1/1 [==============================] - 0s 301ms/step\n","1/1 [==============================] - 0s 473ms/step\n","1/1 [==============================] - 0s 431ms/step\n","1/1 [==============================] - 0s 452ms/step\n","1/1 [==============================] - 1s 519ms/step\n","1/1 [==============================] - 0s 462ms/step\n","1/1 [==============================] - 0s 415ms/step\n","1/1 [==============================] - 0s 250ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 267ms/step\n","1/1 [==============================] - 0s 251ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 267ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 252ms/step\n","1/1 [==============================] - 0s 245ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 259ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 252ms/step\n","1/1 [==============================] - 0s 246ms/step\n","1/1 [==============================] - 0s 242ms/step\n","1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 241ms/step\n","1/1 [==============================] - 0s 246ms/step\n","1/1 [==============================] - 0s 273ms/step\n","1/1 [==============================] - 0s 250ms/step\n","1/1 [==============================] - 0s 274ms/step\n","1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 483ms/step\n","1/1 [==============================] - 0s 459ms/step\n","1/1 [==============================] - 0s 434ms/step\n","1/1 [==============================] - 0s 417ms/step\n","1/1 [==============================] - 0s 464ms/step\n","1/1 [==============================] - 0s 436ms/step\n","1/1 [==============================] - 0s 296ms/step\n","1/1 [==============================] - 0s 252ms/step\n","1/1 [==============================] - 0s 240ms/step\n","1/1 [==============================] - 0s 269ms/step\n","1/1 [==============================] - 0s 251ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 274ms/step\n","1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 262ms/step\n","1/1 [==============================] - 0s 242ms/step\n","1/1 [==============================] - 0s 242ms/step\n","1/1 [==============================] - 0s 261ms/step\n","1/1 [==============================] - 0s 240ms/step\n","1/1 [==============================] - 0s 261ms/step\n","1/1 [==============================] - 0s 245ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 250ms/step\n","1/1 [==============================] - 0s 258ms/step\n","1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 252ms/step\n","1/1 [==============================] - 0s 232ms/step\n","1/1 [==============================] - 0s 297ms/step\n","1/1 [==============================] - 0s 241ms/step\n","1/1 [==============================] - 0s 236ms/step\n","1/1 [==============================] - 0s 329ms/step\n","1/1 [==============================] - 0s 432ms/step\n","1/1 [==============================] - 0s 423ms/step\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:09:14] \"POST /predict HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:09:15] \"GET /static/uploads/CXR1_1_IM-0001-3001.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:09:15] \"GET /static/uploads/CXR1_1_IM-0001-4001.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:09:15] \"GET /static/styles/predict.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:12:06] \"GET /home HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:12:07] \"\u001b[36mGET /static/styles/index.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:12:07] \"\u001b[36mGET /static/js/myjs.js HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:12:28] \"GET /home HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:12:29] \"\u001b[36mGET /static/styles/index.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:12:29] \"\u001b[36mGET /static/js/myjs.js HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:21:15] \"GET /logout HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:21:16] \"\u001b[36mGET /static/styles/mystyle.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:29:03] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:29:04] \"\u001b[36mGET /static/styles/index.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:29:04] \"\u001b[36mGET /static/js/myjs.js HTTP/1.1\u001b[0m\" 304 -\n"]},{"name":"stdout","output_type":"stream","text":["test0.png\n","test00.png\n","1/1 [==============================] - 0s 259ms/step\n","1/1 [==============================] - 0s 263ms/step\n","1/1 [==============================] - 0s 240ms/step\n","1/1 [==============================] - 0s 230ms/step\n","1/1 [==============================] - 0s 238ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 240ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 257ms/step\n","1/1 [==============================] - 0s 245ms/step\n","1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 291ms/step\n","1/1 [==============================] - 0s 292ms/step\n","1/1 [==============================] - 0s 251ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 265ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 250ms/step\n","1/1 [==============================] - 0s 261ms/step\n","1/1 [==============================] - 0s 240ms/step\n","1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 411ms/step\n","1/1 [==============================] - 0s 435ms/step\n","1/1 [==============================] - 0s 408ms/step\n","1/1 [==============================] - 0s 420ms/step\n","1/1 [==============================] - 0s 428ms/step\n","1/1 [==============================] - 0s 428ms/step\n","1/1 [==============================] - 0s 426ms/step\n","1/1 [==============================] - 0s 250ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 269ms/step\n","1/1 [==============================] - 0s 241ms/step\n","1/1 [==============================] - 0s 238ms/step\n","1/1 [==============================] - 0s 259ms/step\n","1/1 [==============================] - 0s 232ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 272ms/step\n","1/1 [==============================] - 0s 311ms/step\n","1/1 [==============================] - 0s 241ms/step\n","1/1 [==============================] - 0s 254ms/step\n","1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 261ms/step\n","1/1 [==============================] - 0s 314ms/step\n","1/1 [==============================] - 0s 262ms/step\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:29:43] \"POST /predict HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:29:44] \"GET /static/uploads/test0.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:29:44] \"\u001b[36mGET /static/styles/predict.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:29:44] \"GET /static/uploads/test00.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:30:08] \"GET /home HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:30:09] \"\u001b[36mGET /static/styles/index.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:30:09] \"\u001b[36mGET /static/js/myjs.js HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:30:11] \"GET /logout HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:30:11] \"\u001b[36mGET /static/styles/mystyle.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:01] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:02] \"\u001b[36mGET /static/styles/index.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:02] \"\u001b[36mGET /static/js/myjs.js HTTP/1.1\u001b[0m\" 304 -\n"]},{"name":"stdout","output_type":"stream","text":["test0.png\n","test00.png\n","1/1 [==============================] - 0s 432ms/step\n","1/1 [==============================] - 0s 436ms/step\n","1/1 [==============================] - 0s 441ms/step\n","1/1 [==============================] - 0s 447ms/step\n","1/1 [==============================] - 0s 425ms/step\n","1/1 [==============================] - 0s 260ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 260ms/step\n","1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 259ms/step\n","1/1 [==============================] - 0s 238ms/step\n","1/1 [==============================] - 0s 227ms/step\n","1/1 [==============================] - 0s 259ms/step\n","1/1 [==============================] - 0s 262ms/step\n","1/1 [==============================] - 0s 264ms/step\n","1/1 [==============================] - 0s 266ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 250ms/step\n","1/1 [==============================] - 0s 298ms/step\n","1/1 [==============================] - 0s 258ms/step\n","1/1 [==============================] - 0s 276ms/step\n","1/1 [==============================] - 0s 279ms/step\n","1/1 [==============================] - 0s 236ms/step\n","1/1 [==============================] - 0s 241ms/step\n","1/1 [==============================] - 0s 257ms/step\n","1/1 [==============================] - 0s 260ms/step\n","1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 242ms/step\n","1/1 [==============================] - 0s 335ms/step\n","1/1 [==============================] - 0s 429ms/step\n","1/1 [==============================] - 0s 433ms/step\n","1/1 [==============================] - 0s 414ms/step\n","1/1 [==============================] - 0s 445ms/step\n","1/1 [==============================] - 0s 438ms/step\n","1/1 [==============================] - 0s 440ms/step\n","1/1 [==============================] - 0s 419ms/step\n","1/1 [==============================] - 0s 379ms/step\n","1/1 [==============================] - 0s 302ms/step\n","1/1 [==============================] - 0s 257ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 246ms/step\n","1/1 [==============================] - 0s 275ms/step\n","1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 237ms/step\n","1/1 [==============================] - 0s 275ms/step\n","1/1 [==============================] - 0s 288ms/step\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:41] \"POST /predict HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:41] \"GET /static/uploads/test0.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:41] \"\u001b[36mGET /static/styles/predict.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:41] \"GET /static/uploads/test00.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:48] \"GET /home HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:49] \"\u001b[36mGET /static/js/myjs.js HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:45:49] \"\u001b[36mGET /static/styles/index.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"name":"stdout","output_type":"stream","text":["test11.png\n","test1.png\n","1/1 [==============================] - 0s 294ms/step\n","1/1 [==============================] - 0s 264ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 256ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 261ms/step\n","1/1 [==============================] - 0s 257ms/step\n","1/1 [==============================] - 0s 249ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 246ms/step\n","1/1 [==============================] - 0s 251ms/step\n","1/1 [==============================] - 0s 242ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 259ms/step\n","1/1 [==============================] - 0s 235ms/step\n","1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 246ms/step\n","1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 269ms/step\n","1/1 [==============================] - 0s 338ms/step\n","1/1 [==============================] - 0s 473ms/step\n","1/1 [==============================] - 0s 449ms/step\n","1/1 [==============================] - 0s 419ms/step\n","1/1 [==============================] - 0s 400ms/step\n","1/1 [==============================] - 0s 493ms/step\n","1/1 [==============================] - 0s 344ms/step\n","1/1 [==============================] - 0s 297ms/step\n","1/1 [==============================] - 0s 242ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 270ms/step\n","1/1 [==============================] - 0s 238ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 244ms/step\n","1/1 [==============================] - 0s 246ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 242ms/step\n","1/1 [==============================] - 0s 251ms/step\n","1/1 [==============================] - 0s 259ms/step\n","1/1 [==============================] - 0s 240ms/step\n","1/1 [==============================] - 0s 240ms/step\n","1/1 [==============================] - 0s 253ms/step\n","1/1 [==============================] - 0s 256ms/step\n","1/1 [==============================] - 0s 239ms/step\n","1/1 [==============================] - 0s 242ms/step\n","1/1 [==============================] - 0s 239ms/step\n","1/1 [==============================] - 0s 263ms/step\n","1/1 [==============================] - 0s 255ms/step\n","1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 280ms/step\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:46:26] \"POST /predict HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:46:26] \"\u001b[36mGET /static/styles/predict.css HTTP/1.1\u001b[0m\" 304 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:46:26] \"GET /static/uploads/test11.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [10/Mar/2025 06:46:26] \"GET /static/uploads/test1.png HTTP/1.1\" 200 -\n"]}],"source":["def load_image(img_name):\n","  \"\"\"Loads image in array format\"\"\"\n","\n","  image = Image.open(img_name)\n","  X = np.asarray(image.convert(\"RGB\"))\n","  X = np.asarray(X)\n","  X = preprocess_input(X)\n","  X = resize(X, (256,256,3))\n","  X = np.expand_dims(X, axis=0)\n","  X = np.asarray(X)\n","\n","  return X\n","\n","def preprocess(image1_path,image2_path):\n","  '''\n","    input -- dataframe(df)\n","    output -- dataframe(df)\n","    process - convert images into 256 X 256, then using CHeXNET model generate tensor(concate two image tensor)\n","  '''\n","  path = '/content/images/'\n","\n","  image_features = []\n","  for i in range(len(image1_path)):\n","\n","    i1 = load_image(image1_path)\n","    i2 = load_image(image2_path)\n","    img1_features = model.predict(i1)\n","    img2_features = model.predict(i2)\n","    img1_features = np.vstack(img1_features).astype(np.float)\n","    img2_features = np.vstack(img2_features).astype(np.float)\n","\n","    tensor = np.concatenate((img1_features, img2_features), axis=1)\n","\n","  return tensor\n","\n","\n","def predict_report(image1, image2):\n","    '''\n","    Input - two image and image path\n","    output - return medical report of the images\n","    This function takes images and using encoder decoder model\n","    return medical report of the images\n","    The function predicts the sentence using beam search\n","    '''\n","\n","    img_tensor     = preprocess(image1, image2)\n","    image_features = np.vstack(img_tensor).astype(np.float)\n","\n","    result = ''\n","    initial_state  = Attention_model.layers[0].initialize_states(1)\n","    sequences      = [['\u003cstart\u003e', initial_state, 0]]\n","\n","    encoder_output       = Attention_model.layers[0](image_features)\n","    decoder_hidden_state = initial_state\n","\n","    max_len = 75\n","    beam_width = 3\n","    finished_seq = []\n","\n","    for i in range(max_len):\n","        new_seq = []\n","        all_probable = []\n","\n","        for seq,state,score in sequences:\n","\n","            cur_vec = np.reshape(word_idx[seq.split(\" \")[-1]],(1,1))\n","            decoder_hidden_state = state\n","            x = [cur_vec, encoder_output, decoder_hidden_state]\n","            output,hidden_state,att_weights,context_vector = Attention_model.get_layer('decoder').onestepdecoder(x)\n","            output = tf.nn.softmax(output)\n","            top_words = np.argsort(output).flatten()[-beam_width:]\n","            for index in top_words:\n","\n","                predicted = [seq + ' '+ idx_word[index], hidden_state, score-np.log(np.array(output).flatten()[index])]\n","                all_probable.append(predicted)\n","\n","        sequences = sorted(all_probable, key = lambda l: l[2])[:beam_width]\n","\n","        count = 0\n","        for seq,state,score in sequences:\n","            if seq.split(\" \")[-1] == '\u003cend\u003e':\n","                score = score/len(seq)\n","                finished_seq.append([seq,state,score])\n","                count+=1\n","            else:\n","                new_seq.append([seq,state,score])\n","\n","        sequences = new_seq\n","        beam_width= beam_width - count\n","        if not sequences:\n","            break\n","        else:\n","            continue\n","\n","    if len(finished_seq) \u003e0:\n","          finished_seq = sorted(finished_seq, reverse=True, key = lambda l: l[2])\n","          sequences = finished_seq[-1]\n","          return sequences[0][8:-5]\n","    else:\n","          return new_seq[-1][0]\n","\n","\n","from flask import Flask, render_template, request , redirect, url_for, session\n","from werkzeug.utils import secure_filename\n","import os\n","from flask_ngrok import run_with_ngrok\n","\n","\n","\n","template_folder='templates'\n","static_folder='static'\n","\n","app = Flask(__name__, template_folder=template_folder, static_folder=static_folder)\n","\n","ngrok.set_auth_token('2tw2hVGVy5gjl9Tjltx9M4N8j4k_XvtVJELukuPAvfT5hC1Q')\n","# Specify the port within the config dictionary:\n","public_url = ngrok.connect(bind_tls=True, addr=5000).public_url\n","print(public_url)\n","\n","\n","# Ensure static/uploads exists\n","UPLOAD_FOLDER = 'static/uploads'\n","\n","os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n","\n","app.secret_key = 'your_secret_key'  # Needed for session management\n","@app.route(\"/\",methods=['GET','POST'])\n","def login():\n","  USER= 'admin'\n","  PASSWORD= 'admin'\n","  if request.method=='POST':\n","    username= request.form['username']\n","    password= request.form['password']\n","\n","    if username==USER and password==PASSWORD:\n","      session['logged_in'] = True  # Set session variable\n","      return render_template(\"index.html\")\n","    else:\n","      message= \"Wrong username or password. Try again!\"\n","      return render_template(\"login.html\", message=message)\n","\n","  else:\n","    return render_template(\"login.html\")\n","\n","\n","@app.route(\"/logout\")\n","def logout():\n","    session.pop('logged_in', None)  # Remove session variable\n","    return render_template(\"login.html\")\n","\n","\n","\n","@app.route('/home')\n","def home():\n","  # if not session.get('logged_in'):  # Check if user is logged in\n","  #       return render_template(\"login.html\")\n","  return render_template('index.html')\n","\n","\n","\n","\n","\n","@app.route('/predict',methods=['POST'] )\n","def predict_caption():\n","\n","\n","      front_XRay   = request.files['file_1']\n","      lateral_XRay = request.files['file_2']\n","      print(front_XRay.filename)\n","      print(lateral_XRay.filename)\n","\n","      # Save files in static/uploads/\n","      front_XRay_path = os.path.join(UPLOAD_FOLDER, secure_filename(front_XRay.filename))\n","      lateral_XRay_path = os.path.join(UPLOAD_FOLDER, secure_filename(lateral_XRay.filename))\n","\n","      front_XRay.save(front_XRay_path)\n","      lateral_XRay.save(lateral_XRay_path)\n","\n","      result = predict_report(front_XRay_path,lateral_XRay_path)\n","\n","      return render_template('prediction.html', prediction_text=result, front_XRay=secure_filename(front_XRay.filename), lateral_XRay=secure_filename(lateral_XRay.filename))\n","\n","\n","if __name__ == '__main__':\n","    app.run(port=5000)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wc1Ju8rTgSGh"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOskd5rysMMey1PNUtODR1t","mount_file_id":"1m8tFr_ZbcxfhM0iDFHRwJiBagQjZs31p","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}